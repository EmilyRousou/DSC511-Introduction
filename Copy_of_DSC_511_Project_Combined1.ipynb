{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilyRousou/DSC511-Introduction/blob/main/Copy_of_DSC_511_Project_Combined1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DSC 511 Group Project"
      ],
      "metadata": {
        "id": "W7AADmpKRkA2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMswIgdMaJBx",
        "outputId": "86dcd43c-e099-4c86-ad3b-d0211d38a48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Installing pyspark\n",
        "! pip3 install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from pyspark.sql.functions import lower, regexp_replace\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "from pyspark.ml.clustering import LDA\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import IDF\n",
        "from pyspark.sql.functions import expr\n",
        "from pyspark.ml.linalg import Vectors, DenseVector\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, DoubleType\n",
        "from pyspark.sql.functions import avg, count, col"
      ],
      "metadata": {
        "id": "Hu4hr54Sy3rs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Group_Project_Reviews_Covid\") \\\n",
        "    .master(\"local\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "otW_HDezSamD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the datasets"
      ],
      "metadata": {
        "id": "b-MSc98ITBqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive and reading the csv of post dataset\n",
        "drive.mount('/content/gdrive')\n",
        "google_drive_path = \"/content/gdrive/MyDrive/postcovid_reviews.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQenpOIKSzaw",
        "outputId": "b0e21f9f-74f3-4ab2-c3a3-c9f8edd6f666"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive and reading the csv of pre dataset\n",
        "drive.mount('/content/gdrive')\n",
        "google_drive = \"/content/gdrive/MyDrive/precovid_reviews.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT0bAYyYTQvV",
        "outputId": "347eb5d2-9a24-4b38-90e0-1c2acd5aff75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_df = spark.read.options(header='True', inferSchema='True', delimiter=',',multiline = True, escape = '\"').csv(google_drive_path)"
      ],
      "metadata": {
        "id": "1uO785JqWkeJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df = spark.read.options(header='True', inferSchema='True', delimiter=',',multiline = True, escape = '\"').csv(google_drive)"
      ],
      "metadata": {
        "id": "_JxuGktXTzy3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_df_parquet = post_df.write.parquet(\"data/output_parquet\", mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "D_IE_QRjZb8J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHs6eaKqaKHv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}